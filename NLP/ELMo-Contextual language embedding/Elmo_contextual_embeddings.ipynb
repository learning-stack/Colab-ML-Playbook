{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Elmo contextual embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ZU3MR71VpovV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ELMo: Contextual language embedding\n",
        "\n",
        "## by Josh Taylor\n",
        "\n",
        "Note that you will need to use the non-GPU accelerated run-time on this notebook due to the large memory useage of the ELMo model."
      ]
    },
    {
      "metadata": {
        "id": "GdKJLTIlxh1G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/elmo-contextual-language-embedding-335de2268604"
      ]
    },
    {
      "metadata": {
        "id": "rrDju1JSxWGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/learning-stack/Colab-ML-Playbook/blob/master/NLP/ELMo-Contextual%20language%20embedding/Elmo_contextual_embeddings.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/learning-stack/Colab-ML-Playbook/blob/master/NLP/ELMo-Contextual%20language%20embedding/Elmo_contextual_embeddings.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "-q8JYD36CdYr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports:"
      ]
    },
    {
      "metadata": {
        "id": "_Qgy7Jmr5wSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn import preprocessing\n",
        "\n",
        "!python -m spacy download en_core_web_md #you will need to install this on first load\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy import displacy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RdjjrAa-_RST",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Get the text data, clean and tokenize**\n",
        "\n",
        "It is amazing how simple this is to do using Python string functions and spaCy. Here we do some basic text cleaning by:\n",
        "\n",
        "a) removing line breaks, tabs and excess whitespace as well as the mysterious ‘xa0’ character;\n",
        "\n",
        "b) splitting the text into sentences using spaCy’s ‘.sents’ iterator.\n",
        "\n",
        "ELMo can receive either a list of sentence strings or a list of lists (sentences and words). Here we have gone for the former. We know that ELMo is character based, therefore tokenizing words should not have any impact on performance."
      ]
    },
    {
      "metadata": {
        "id": "0sn1oNBq_QAs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_md')\n",
        "from IPython.display import HTML\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True #OPTIONAL - to disable outputs from Tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WMknjdZpCgR0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get the data \n",
        "\n",
        "The below downloads a Pandas Dataframe which is publically hosted on Google Drive (this should therefore work for anyone)"
      ]
    },
    {
      "metadata": {
        "id": "7_Oy1nXa6dLi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "\n",
        "file_id = '1M_XljfV5t_nGjvhyfTPO9n2nfOweMwYx'\n",
        "destination = 'temp'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "combined = pd.read_pickle('temp')\n",
        "\n",
        "combined.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FxkL4RXwVToa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create sentence embeddings"
      ]
    },
    {
      "metadata": {
        "id": "CoelrCfg_dX8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Get the ELMo model using TensorFlow Hub:**\n",
        "\n",
        "If you have not yet come across TensorFlow Hub, it is a massive time saver in serving-up a large number of pre-trained models for use in TensorFlow. Luckily for us, one of these models is ELMo. We can load in a fully trained model in just two few lines of code. How satisfying…"
      ]
    },
    {
      "metadata": {
        "id": "UIhHrFsmOC6C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = \"https://tfhub.dev/google/elmo/2\"\n",
        "embed = hub.Module(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Df76NYQcnQ3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "combined.loc[combined.Company.str.contains(\"Asos\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AU_MS6MXVe_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text = combined.iloc[494].text\n",
        "import re\n",
        "\n",
        "#text represents our raw text document\n",
        "\n",
        "text = text.lower().replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0',' ')\n",
        "text = ' '.join(text.split())\n",
        "doc = nlp(text)\n",
        "\n",
        "sentences = []\n",
        "for i in doc.sents:\n",
        "  if len(i)>1:\n",
        "    sentences.append(i.string.strip())\n",
        "    \n",
        "len(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SjGbrUhapvXE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3XhIMQa_oUE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To then use this model in anger we just need a few more lines of code to point it in the direction of our text document and create sentence vectors:"
      ]
    },
    {
      "metadata": {
        "id": "HsGkzCltOMOl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This tells the model to run through the 'sentences' list and return the default output (1024 dimension sentence vectors).\n",
        "embeddings = embed(\n",
        "    sentences,\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"default\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oA6BO4a_Oswf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Start a session and run ELMo to return the embeddings in variable x\n",
        "\n",
        "%%time\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(tf.tables_initializer())\n",
        "  x = sess.run(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qwlt2Husrtzo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize the sentences using PCA and TSNE"
      ]
    },
    {
      "metadata": {
        "id": "Ylpu0Nqg_uNV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Use visualisation to sense-check outputs**\n",
        "\n",
        "It is amazing how often visualisation is overlooked as a way of gaining greater understanding of data. Pictures speak a thousand words and we are going to create a chart of a thousand words to prove this point (actually it is 8,511 words).\n",
        "\n",
        "Here we will use PCA and t-SNE to reduce the 1,024 dimensions which are output from ELMo down to 2 so that we can review the outputs from the model. I have included further reading on how this is achieved at the end of the article if you want to find out more."
      ]
    },
    {
      "metadata": {
        "id": "xAGj0yJyUD3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "y = pca.fit_transform(x)\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "y = TSNE(n_components=2).fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jeDyJ2SF_2Kd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the amazing Plotly library, we can create a beautiful, interactive plot in no time at all. The below code shows how to render the results of our dimensionality reduction and join this back up to the sentence text. Colour has also been added based on the sentence length. As we are using Colab, the last line of code downloads the HTML file. This can be found below:"
      ]
    },
    {
      "metadata": {
        "id": "KGUyrjcMfdJp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "\n",
        "data = [\n",
        "    go.Scatter(\n",
        "        x=[i[0] for i in y],\n",
        "        y=[i[1] for i in y],\n",
        "        mode='markers',\n",
        "        text=[i for i in sentences],\n",
        "    marker=dict(\n",
        "        size=16,\n",
        "        color = [len(i) for i in sentences], #set color equal to a variable\n",
        "        opacity= 0.8,\n",
        "        colorscale='Viridis',\n",
        "        showscale=False\n",
        "    )\n",
        "    )\n",
        "]\n",
        "layout = go.Layout()\n",
        "layout = dict(\n",
        "              yaxis = dict(zeroline = False),\n",
        "              xaxis = dict(zeroline = False)\n",
        "             )\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "file = plot(fig, filename='Sentence encode.html')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('Sentence encode.html') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eAu1zHOjrzzj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create a semantic search engine:"
      ]
    },
    {
      "metadata": {
        "id": "HfgIfOxXQ8ba",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Sementic search\n",
        "#@markdown Enter a set of words to find matching sentences. 'results_returned' can beused to modify the number of matching sentences retured. To view the code behind this cell, use the menu in the top right to unhide...\n",
        "search_string = \"code of ethics\" #@param {type:\"string\"}\n",
        "results_returned = \"3\" #@param [1, 2, 3]\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "embeddings2 = embed(\n",
        "    [search_string],\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"default\"]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(tf.tables_initializer())\n",
        "  search_vect = sess.run(embeddings2)\n",
        "  \n",
        "\n",
        "cosine_similarities = pd.Series(cosine_similarity(search_vect, x).flatten())\n",
        "output =\"\"\n",
        "for i,j in cosine_similarities.nlargest(int(results_returned)).iteritems():\n",
        "  output +='<p style=\"font-family:verdana; font-size:110%;\"> '\n",
        "  for i in sentences[i].split():\n",
        "    if i.lower() in search_string:\n",
        "      output += \" <b>\"+str(i)+\"</b>\"\n",
        "    else:\n",
        "      output += \" \"+str(i)\n",
        "  output += \"</p><hr>\"\n",
        "    \n",
        "output = '<h3>Results:</h3>'+output\n",
        "display(HTML(output))\n",
        "#   print(sentences[i])\n",
        "#   print('\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}