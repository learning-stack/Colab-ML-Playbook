{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-label-classification-with-keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "_uuid": "3069af84cb76189b9bf10874ba99d6d1e237bbe5",
        "id": "0fp_i_DpzeEt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Multi-label text classification with keras\n",
        "## by Rocco Schulz\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "B4vzMz8BzrQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://blog.mimacom.com/text-classification/"
      ]
    },
    {
      "metadata": {
        "id": "sOswLb8Gzsr8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/multi-label-classification-with-keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/multi-label-classification-with-keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "ot025wGezeEw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "20X58OAC315O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download data files\n",
        "!wget https://github.com/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Questions.csv?raw=true\n",
        "!wget https://github.com/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Tags.csv?raw=true\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "vgGHBOPbzeE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_questions = pd.read_csv('Questions.csv?raw=true', encoding='iso-8859-1')\n",
        "df_tags = pd.read_csv('Tags.csv?raw=true', encoding='iso-8859-1')\n",
        "df_questions.head(n=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3cb05d6b416914c26d66531e8e521f5e412c11af",
        "id": "7xON3PQqzeE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grouped_tags = df_tags.groupby(\"Tag\", sort='count').size().reset_index(name='count')\n",
        "grouped_tags.Tag.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "93f06b61db6e2b42fd6c1537841f919892211975",
        "id": "krZ-L2etzeE6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reducing the problem to the most common tags in the dataset\n",
        "We only use the top 100 (arbitrarily picked number) tags because for rare tags there are simply not enough samples available to get reliable results."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7af43d023d87159a669f6678dc79f4886fb677e9",
        "id": "xi5FtHcrzeE8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 100\n",
        "grouped_tags = df_tags.groupby(\"Tag\").size().reset_index(name='count')\n",
        "most_common_tags = grouped_tags.nlargest(num_classes, columns=\"count\")\n",
        "df_tags.Tag = df_tags.Tag.apply(lambda tag : tag if tag in most_common_tags.Tag.values else None)\n",
        "df_tags = df_tags.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "340f6c140f1e69676e5c63c5af2cc3c9ff31be7d",
        "id": "UUpZS-7-zeE_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing the contents of the dataframe\n",
        "\n",
        "The question body contains html tags that we don't want to feed into our model. We will thus strip all tags and combine title and question body into a single field for simplicity."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9bed5c95c0a39c535bfb36e721272c40a42077f5",
        "id": "UABr0t1nzeFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re \n",
        "\n",
        "def strip_html_tags(body):\n",
        "    regex = re.compile('<.*?>')\n",
        "    return re.sub(regex, '', body)\n",
        "\n",
        "df_questions['Body'] = df_questions['Body'].apply(strip_html_tags)\n",
        "df_questions['Text'] = df_questions['Title'] + ' ' + df_questions['Body']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "361bcf1624ad1c6c15aa6287772cd1acb6182368",
        "id": "2kJXRwtPzeFD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# denormalize tables\n",
        "\n",
        "def tags_for_question(question_id):\n",
        "    return df_tags[df_tags['Id'] == question_id].Tag.values\n",
        "\n",
        "def add_tags_column(row):\n",
        "    row['Tags'] = tags_for_question(row['Id'])\n",
        "    return row\n",
        "\n",
        "df_questions = df_questions.apply(add_tags_column, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3788b41a2b7eae538146f9f59dd2c08ede44889",
        "id": "P7XHIPMozeFG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 400)\n",
        "df_questions[['Id', 'Text', 'Tags']].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "80afc34addf7ea5b6e4d08c3af3568d57e21a626",
        "id": "3b0wE_m_zeFL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenizing the text\n",
        "The text has to be vectorized so that we can feed it into our model. Keras comes with [several text preprocessing classes](https://keras.io/preprocessing/text/) that we can use for that.\n",
        "\n",
        "The labels need encoded as well, so that the 100 labels will be represented as 100 binary values in an array. This can be done with the [MultiLabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) from the sklearn library."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8bfc23b1e715e60425e861f855d9848e97942069",
        "id": "3crroU22zeFN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "multilabel_binarizer = MultiLabelBinarizer()\n",
        "multilabel_binarizer.fit(df_questions.Tags)\n",
        "labels = multilabel_binarizer.classes_\n",
        "\n",
        "maxlen = 180\n",
        "max_words = 5000\n",
        "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
        "tokenizer.fit_on_texts(df_questions.Text)\n",
        "\n",
        "def get_features(text_series):\n",
        "    \"\"\"\n",
        "    transforms text data to feature_vectors that can be used in the ml model.\n",
        "    tokenizer must be available.\n",
        "    \"\"\"\n",
        "    sequences = tokenizer.texts_to_sequences(text_series)\n",
        "    return pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "\n",
        "def prediction_to_label(prediction):\n",
        "    tag_prob = [(labels[i], prob) for i, prob in enumerate(prediction.tolist())]\n",
        "    return dict(sorted(tag_prob, key=lambda kv: kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ee229fc276c7ef58ee21e06e5d9694bea7f81c8",
        "id": "MU2Xq6LkzeFR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = get_features(df_questions.Text)\n",
        "y = multilabel_binarizer.transform(df_questions.Tags)\n",
        "print(x.shape)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0148c095b2f97a53511097f560a07124c2136efb",
        "id": "gEdfGbuRzeFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imbalanced Classes\n",
        "Some tags occur more often than others, thus the classes are not well balanced. The imbalanced class problem can be addressed by applying class weights, thus  weighting less frequent tags higher than very frequent tags."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5f0d7d29d627b5f8cd7f18486c3e9cfe93955e9",
        "id": "uYN7owXYzeFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "most_common_tags['class_weight'] = len(df_tags) / most_common_tags['count']\n",
        "class_weight = {}\n",
        "for index, label in enumerate(labels):\n",
        "    class_weight[index] = most_common_tags[most_common_tags['Tag'] == label]['class_weight'].values[0]\n",
        "    \n",
        "most_common_tags.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9be5f3113d27c68fc9456cb18ba9d38d94bb0ebf",
        "id": "DAL-muKtzeFX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building a 1D Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e63351f66ae4bbb63aefd00279d8351e8f7fa8c",
        "id": "DYUnGTTtzeFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "filter_length = 300\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(), \n",
        "    EarlyStopping(patience=4), \n",
        "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    class_weight=class_weight,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41f00f6b8cf514553e442ac6b4d356f69bdc054e",
        "id": "JwtbKF7KzeFc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnn_model = keras.models.load_model('model-conv1d.h5')\n",
        "metrics = cnn_model.evaluate(x_test, y_test)\n",
        "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
        "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}