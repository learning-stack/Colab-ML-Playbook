{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-label-classification-with-keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "_uuid": "3069af84cb76189b9bf10874ba99d6d1e237bbe5",
        "id": "0fp_i_DpzeEt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Multi-label text classification with keras\n",
        "## by Rocco Schulz\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "B4vzMz8BzrQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://blog.mimacom.com/text-classification/"
      ]
    },
    {
      "metadata": {
        "id": "sOswLb8Gzsr8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/multi-label-classification-with-keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/multi-label-classification-with-keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "ot025wGezeEw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "20X58OAC315O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "dc6cbbac-52ff-44dc-f4e1-616dbc247c24"
      },
      "cell_type": "code",
      "source": [
        "# Download data files\n",
        "!wget https://github.com/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Questions.csv?raw=true\n",
        "!wget https://github.com/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Tags.csv?raw=true\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-04 17:22:39--  https://github.com/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Questions.csv?raw=true\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/learning-stack/Colab-ML-Playbook/raw/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Questions.csv [following]\n",
            "--2019-01-04 17:22:39--  https://github.com/learning-stack/Colab-ML-Playbook/raw/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Questions.csv\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/learning-stack/Colab-ML-Playbook/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Questions.csv [following]\n",
            "--2019-01-04 17:22:39--  https://raw.githubusercontent.com/learning-stack/Colab-ML-Playbook/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Questions.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 104276279 (99M) [text/plain]\n",
            "Saving to: ‘Questions.csv?raw=true’\n",
            "\n",
            "Questions.csv?raw=t 100%[===================>]  99.45M  52.1MB/s    in 1.9s    \n",
            "\n",
            "2019-01-04 17:22:42 (52.1 MB/s) - ‘Questions.csv?raw=true’ saved [104276279/104276279]\n",
            "\n",
            "--2019-01-04 17:22:42--  https://github.com/learning-stack/Colab-ML-Playbook/blob/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Tags.csv?raw=true\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/learning-stack/Colab-ML-Playbook/raw/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Tags.csv [following]\n",
            "--2019-01-04 17:22:42--  https://github.com/learning-stack/Colab-ML-Playbook/raw/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Tags.csv\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/learning-stack/Colab-ML-Playbook/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Tags.csv [following]\n",
            "--2019-01-04 17:22:43--  https://raw.githubusercontent.com/learning-stack/Colab-ML-Playbook/master/NLP/Performing%20Multi-label%20Text%20Classification%20with%20Keras/data/Tags.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4653766 (4.4M) [text/plain]\n",
            "Saving to: ‘Tags.csv?raw=true’\n",
            "\n",
            "Tags.csv?raw=true   100%[===================>]   4.44M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-01-04 17:22:43 (42.5 MB/s) - ‘Tags.csv?raw=true’ saved [4653766/4653766]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "vgGHBOPbzeE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "dcc2c996-05d8-48e3-b715-90aa10e631d4"
      },
      "cell_type": "code",
      "source": [
        "df_questions = pd.read_csv('Questions.csv?raw=true', encoding='iso-8859-1')\n",
        "df_tags = pd.read_csv('Tags.csv?raw=true', encoding='iso-8859-1')\n",
        "df_questions.head(n=2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>OwnerUserId</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2010-07-19T19:14:44Z</td>\n",
              "      <td>272</td>\n",
              "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
              "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>59.0</td>\n",
              "      <td>2010-07-19T19:24:36Z</td>\n",
              "      <td>4</td>\n",
              "      <td>Forecasting demographic census</td>\n",
              "      <td>&lt;p&gt;What are some of the ways to forecast demog...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  OwnerUserId          CreationDate  Score  \\\n",
              "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
              "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
              "\n",
              "                                               Title  \\\n",
              "0  The Two Cultures: statistics vs. machine learn...   \n",
              "1                     Forecasting demographic census   \n",
              "\n",
              "                                                Body  \n",
              "0  <p>Last year, I read a blog post from <a href=...  \n",
              "1  <p>What are some of the ways to forecast demog...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3cb05d6b416914c26d66531e8e521f5e412c11af",
        "id": "7xON3PQqzeE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f517a991-6417-4709-d910-0ef5bd4cb00c"
      },
      "cell_type": "code",
      "source": [
        "grouped_tags = df_tags.groupby(\"Tag\", sort='count').size().reset_index(name='count')\n",
        "grouped_tags.Tag.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count                1315\n",
              "unique               1315\n",
              "top       crostons-method\n",
              "freq                    1\n",
              "Name: Tag, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "93f06b61db6e2b42fd6c1537841f919892211975",
        "id": "krZ-L2etzeE6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reducing the problem to the most common tags in the dataset\n",
        "For rare tags there were simply not enough samples available to get reliable results, thus only the top 100 tags were kept. But even with only the 100 most frequently used tags there is still an imbalance as some tags are used more often than others.\n",
        "\n",
        " ![first vs last 5 tags](https://blog.mimacom.com/en/media/ef1a71298726a6f3babd46e9e2988fa1/first_vs_last_5_tags.png)\n",
        "\n",
        "To address this imbalance we calculated class weights to be used as parameters for the loss function of our model. By multiplying the class weights with the categorical losses we can counter the imbalance, so that making false classifications for the tag algorithms is equally expensive as for the tag r.\n",
        "The calculated class weights are plotted against the counts of the tags below.\n",
        "\n",
        " ![class weights plotted vs class observations](https://blog.mimacom.com/en/media/ba1508ba102ac1f7ddb254e9ba06d5a3/class-weights.png)\n",
        "\n",
        "There are alternative ways to address class imbalances. We could also have used resampling to duplicate samples in under-represented classes or reduce the number of samples in over-represented classes or trained several models with balanced subsets of the data and model averaging. (cf. Longadge2013) For resampling there is a scikit-learn compatible library imbalanced-learn which also illustrates the class imbalance problem and supported resampling strategies in its documentation."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7af43d023d87159a669f6678dc79f4886fb677e9",
        "id": "xi5FtHcrzeE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        },
        "outputId": "29667cc9-d51b-4aea-c120-ff4aeea29c4b"
      },
      "cell_type": "code",
      "source": [
        "num_classes = 100\n",
        "grouped_tags = df_tags.groupby(\"Tag\").size().reset_index(name='count')\n",
        "most_common_tags = grouped_tags.nlargest(num_classes, columns=\"count\")\n",
        "df_tags.Tag = df_tags.Tag.apply(lambda tag : tag if tag in most_common_tags.Tag.values else None)\n",
        "df_tags = df_tags.dropna()\n",
        "df_tags"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>bayesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>distributions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>distributions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4</td>\n",
              "      <td>statistical-significance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6</td>\n",
              "      <td>machine-learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7</td>\n",
              "      <td>dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>10</td>\n",
              "      <td>ordinal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>17</td>\n",
              "      <td>anova</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>17</td>\n",
              "      <td>chi-squared</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>17</td>\n",
              "      <td>generalized-linear-model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>21</td>\n",
              "      <td>forecasting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>22</td>\n",
              "      <td>bayesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>23</td>\n",
              "      <td>distributions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>23</td>\n",
              "      <td>pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>25</td>\n",
              "      <td>modeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>25</td>\n",
              "      <td>time-series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>26</td>\n",
              "      <td>standard-deviation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>30</td>\n",
              "      <td>algorithms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>30</td>\n",
              "      <td>hypothesis-testing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>30</td>\n",
              "      <td>random-variable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>31</td>\n",
              "      <td>hypothesis-testing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>31</td>\n",
              "      <td>t-test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>31</td>\n",
              "      <td>p-value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>31</td>\n",
              "      <td>interpretation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>33</td>\n",
              "      <td>r</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>35</td>\n",
              "      <td>distributions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>35</td>\n",
              "      <td>modeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>35</td>\n",
              "      <td>poisson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>36</td>\n",
              "      <td>correlation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>39</td>\n",
              "      <td>modeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244182</th>\n",
              "      <td>241455</td>\n",
              "      <td>distributions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244184</th>\n",
              "      <td>241458</td>\n",
              "      <td>regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244185</th>\n",
              "      <td>241458</td>\n",
              "      <td>multiple-regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244186</th>\n",
              "      <td>241458</td>\n",
              "      <td>repeated-measures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244187</th>\n",
              "      <td>241459</td>\n",
              "      <td>spss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244188</th>\n",
              "      <td>241459</td>\n",
              "      <td>repeated-measures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244189</th>\n",
              "      <td>241461</td>\n",
              "      <td>probability</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244190</th>\n",
              "      <td>241461</td>\n",
              "      <td>sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244193</th>\n",
              "      <td>241464</td>\n",
              "      <td>regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244194</th>\n",
              "      <td>241464</td>\n",
              "      <td>regression-coefficients</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244195</th>\n",
              "      <td>241464</td>\n",
              "      <td>residuals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244197</th>\n",
              "      <td>241465</td>\n",
              "      <td>statistical-significance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244198</th>\n",
              "      <td>241465</td>\n",
              "      <td>modeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244202</th>\n",
              "      <td>241466</td>\n",
              "      <td>regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244203</th>\n",
              "      <td>241466</td>\n",
              "      <td>hypothesis-testing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244204</th>\n",
              "      <td>241466</td>\n",
              "      <td>correlation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244206</th>\n",
              "      <td>241468</td>\n",
              "      <td>distributions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244207</th>\n",
              "      <td>241468</td>\n",
              "      <td>statistical-significance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244208</th>\n",
              "      <td>241468</td>\n",
              "      <td>poisson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244210</th>\n",
              "      <td>241470</td>\n",
              "      <td>probability</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244211</th>\n",
              "      <td>241470</td>\n",
              "      <td>mathematical-statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244214</th>\n",
              "      <td>241472</td>\n",
              "      <td>confidence-interval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244215</th>\n",
              "      <td>241473</td>\n",
              "      <td>r</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244216</th>\n",
              "      <td>241473</td>\n",
              "      <td>optimization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244220</th>\n",
              "      <td>241475</td>\n",
              "      <td>categorical-data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244222</th>\n",
              "      <td>241479</td>\n",
              "      <td>r</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244223</th>\n",
              "      <td>241479</td>\n",
              "      <td>machine-learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244224</th>\n",
              "      <td>241480</td>\n",
              "      <td>mathematical-statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244225</th>\n",
              "      <td>241481</td>\n",
              "      <td>normal-distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244226</th>\n",
              "      <td>241481</td>\n",
              "      <td>estimation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152913 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id                       Tag\n",
              "0            1                  bayesian\n",
              "3            2             distributions\n",
              "7            4             distributions\n",
              "8            4  statistical-significance\n",
              "9            6          machine-learning\n",
              "10           7                   dataset\n",
              "16          10                   ordinal\n",
              "21          17                     anova\n",
              "22          17               chi-squared\n",
              "23          17  generalized-linear-model\n",
              "24          21               forecasting\n",
              "27          22                  bayesian\n",
              "29          23             distributions\n",
              "30          23                       pdf\n",
              "32          25                  modeling\n",
              "33          25               time-series\n",
              "36          26        standard-deviation\n",
              "38          30                algorithms\n",
              "39          30        hypothesis-testing\n",
              "40          30           random-variable\n",
              "42          31        hypothesis-testing\n",
              "43          31                    t-test\n",
              "44          31                   p-value\n",
              "45          31            interpretation\n",
              "47          33                         r\n",
              "49          35             distributions\n",
              "50          35                  modeling\n",
              "51          35                   poisson\n",
              "53          36               correlation\n",
              "55          39                  modeling\n",
              "...        ...                       ...\n",
              "244182  241455             distributions\n",
              "244184  241458                regression\n",
              "244185  241458       multiple-regression\n",
              "244186  241458         repeated-measures\n",
              "244187  241459                      spss\n",
              "244188  241459         repeated-measures\n",
              "244189  241461               probability\n",
              "244190  241461                  sampling\n",
              "244193  241464                regression\n",
              "244194  241464   regression-coefficients\n",
              "244195  241464                 residuals\n",
              "244197  241465  statistical-significance\n",
              "244198  241465                  modeling\n",
              "244202  241466                regression\n",
              "244203  241466        hypothesis-testing\n",
              "244204  241466               correlation\n",
              "244206  241468             distributions\n",
              "244207  241468  statistical-significance\n",
              "244208  241468                   poisson\n",
              "244210  241470               probability\n",
              "244211  241470   mathematical-statistics\n",
              "244214  241472       confidence-interval\n",
              "244215  241473                         r\n",
              "244216  241473              optimization\n",
              "244220  241475          categorical-data\n",
              "244222  241479                         r\n",
              "244223  241479          machine-learning\n",
              "244224  241480   mathematical-statistics\n",
              "244225  241481       normal-distribution\n",
              "244226  241481                estimation\n",
              "\n",
              "[152913 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "340f6c140f1e69676e5c63c5af2cc3c9ff31be7d",
        "id": "UUpZS-7-zeE_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing the contents of the dataframe\n",
        "\n",
        "The question body contains html tags that we don't want to feed into our model. We will thus strip all tags and combine title and question body into a single field for simplicity."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9bed5c95c0a39c535bfb36e721272c40a42077f5",
        "id": "UABr0t1nzeFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re \n",
        "\n",
        "def strip_html_tags(body):\n",
        "    regex = re.compile('<.*?>')\n",
        "    return re.sub(regex, '', body)\n",
        "\n",
        "df_questions['Body'] = df_questions['Body'].apply(strip_html_tags)\n",
        "df_questions['Text'] = df_questions['Title'] + ' ' + df_questions['Body']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "361bcf1624ad1c6c15aa6287772cd1acb6182368",
        "id": "2kJXRwtPzeFD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# denormalize tables\n",
        "\n",
        "def tags_for_question(question_id):\n",
        "    return df_tags[df_tags['Id'] == question_id].Tag.values\n",
        "\n",
        "def add_tags_column(row):\n",
        "    row['Tags'] = tags_for_question(row['Id'])\n",
        "    return row\n",
        "\n",
        "df_questions = df_questions.apply(add_tags_column, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3788b41a2b7eae538146f9f59dd2c08ede44889",
        "id": "P7XHIPMozeFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "e6638c39-449f-4d41-cac5-8a668f20d785"
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 400)\n",
        "df_questions[['Id', 'Text', 'Tags']].head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Text</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any c...</td>\n",
              "      <td>[machine-learning]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...</td>\n",
              "      <td>[forecasting]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>Bayesian and frequentist reasoning in plain English How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n</td>\n",
              "      <td>[bayesian]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>What is the meaning of p values and t values in statistical tests? After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the resul...</td>\n",
              "      <td>[hypothesis-testing, t-test, p-value, interpretation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>Examples for teaching: Correlation does not mean causation There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between 'N...</td>\n",
              "      <td>[correlation]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  \\\n",
              "0   6   \n",
              "1  21   \n",
              "2  22   \n",
              "3  31   \n",
              "4  36   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                              Text  \\\n",
              "0  The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any c...   \n",
              "1  Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...   \n",
              "2                                                                                                                                                                                                                                          Bayesian and frequentist reasoning in plain English How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n   \n",
              "3  What is the meaning of p values and t values in statistical tests? After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the resul...   \n",
              "4  Examples for teaching: Correlation does not mean causation There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between 'N...   \n",
              "\n",
              "                                                    Tags  \n",
              "0                                     [machine-learning]  \n",
              "1                                          [forecasting]  \n",
              "2                                             [bayesian]  \n",
              "3  [hypothesis-testing, t-test, p-value, interpretation]  \n",
              "4                                          [correlation]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "80afc34addf7ea5b6e4d08c3af3568d57e21a626",
        "id": "3b0wE_m_zeFL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenizing the text\n",
        "The text has to be vectorized so that we can feed it into our model. Keras comes with [several text preprocessing classes](https://keras.io/preprocessing/text/) that we can use for that.\n",
        "\n",
        "The labels need encoded as well, so that the 100 labels will be represented as 100 binary values in an array. This can be done with the [MultiLabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) from the sklearn library."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8bfc23b1e715e60425e861f855d9848e97942069",
        "id": "3crroU22zeFN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "multilabel_binarizer = MultiLabelBinarizer()\n",
        "multilabel_binarizer.fit(df_questions.Tags)\n",
        "labels = multilabel_binarizer.classes_\n",
        "\n",
        "maxlen = 180\n",
        "max_words = 5000\n",
        "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
        "tokenizer.fit_on_texts(df_questions.Text)\n",
        "\n",
        "def get_features(text_series):\n",
        "    \"\"\"\n",
        "    transforms text data to feature_vectors that can be used in the ml model.\n",
        "    tokenizer must be available.\n",
        "    \"\"\"\n",
        "    sequences = tokenizer.texts_to_sequences(text_series)\n",
        "    return pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "\n",
        "def prediction_to_label(prediction):\n",
        "    tag_prob = [(labels[i], prob) for i, prob in enumerate(prediction.tolist())]\n",
        "    return dict(sorted(tag_prob, key=lambda kv: kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gokrAQFN6dta",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the snippet above only the most frequent 5000 words are used to build a dictionary. We limit the sequence length to 180 words.\n",
        "\n",
        "The labels need to be encoded as well, so that the 100 labels will be represented as 100 binary elements in an array. This was done with the MultiLabelBinarizer from the sklearn library."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ee229fc276c7ef58ee21e06e5d9694bea7f81c8",
        "id": "MU2Xq6LkzeFR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = get_features(df_questions.Text)\n",
        "y = multilabel_binarizer.transform(df_questions.Tags)\n",
        "print(x.shape)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0148c095b2f97a53511097f560a07124c2136efb",
        "id": "gEdfGbuRzeFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imbalanced Classes\n",
        "Some tags occur more often than others, thus the classes are not well balanced. The imbalanced class problem can be addressed by applying class weights, thus  weighting less frequent tags higher than very frequent tags."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5f0d7d29d627b5f8cd7f18486c3e9cfe93955e9",
        "id": "uYN7owXYzeFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "most_common_tags['class_weight'] = len(df_tags) / most_common_tags['count']\n",
        "class_weight = {}\n",
        "for index, label in enumerate(labels):\n",
        "    class_weight[index] = most_common_tags[most_common_tags['Tag'] == label]['class_weight'].values[0]\n",
        "    \n",
        "most_common_tags.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9be5f3113d27c68fc9456cb18ba9d38d94bb0ebf",
        "id": "DAL-muKtzeFX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building a 1D Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e63351f66ae4bbb63aefd00279d8351e8f7fa8c",
        "id": "DYUnGTTtzeFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "filter_length = 300\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(), \n",
        "    EarlyStopping(patience=4), \n",
        "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    class_weight=class_weight,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41f00f6b8cf514553e442ac6b4d356f69bdc054e",
        "id": "JwtbKF7KzeFc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnn_model = keras.models.load_model('model-conv1d.h5')\n",
        "metrics = cnn_model.evaluate(x_test, y_test)\n",
        "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
        "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}